{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqUrnIpoqAHp"
      },
      "source": [
        "# Poetry Notebook\n",
        "\n",
        "In this notebook we will be implementing GPT to generate text based on the work of Edgar Allan Poe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0d5dI4LKXBp",
        "outputId": "7c21f0d8-87cb-44fb-9681-25e9743eaf39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "--2023-05-17 15:08:51--  https://raw.githubusercontent.com/kocenko/Poetry-Synthesis/dev/data/poe_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1930488 (1.8M) [text/plain]\n",
            "Saving to: ‘poe_data.txt’\n",
            "\n",
            "poe_data.txt        100%[===================>]   1.84M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2023-05-17 15:08:53 (280 MB/s) - ‘poe_data.txt’ saved [1930488/1930488]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Installing dependencies\n",
        "!pip install tiktoken\n",
        "!pip install torch\n",
        "\n",
        "# Downloading dataset from the GitHub\n",
        "!wget https://raw.githubusercontent.com/kocenko/Poetry-Synthesis/main/data/poe_data.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PqtdnLBxN3sQ"
      },
      "outputs": [],
      "source": [
        "# Essential imports\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zLSR7xdlPQaN"
      },
      "outputs": [],
      "source": [
        "# Testing if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "\n",
        "CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4K9Stu5Uy3Ym"
      },
      "outputs": [],
      "source": [
        "# Dataset class definition\n",
        "### (Option) We can use different data to train it on\n",
        "### (Option) What if the context affects not the following\n",
        "###          but the one after the following token? (bigger offset)\n",
        "\n",
        "class PoeDataset(Dataset):\n",
        "    valid_split_params = [\"train\", \"valid\"]\n",
        "\n",
        "    def __init__(self, text: str, split: str, split_ratio: float, context_length: int, tokenizer, offset: int = 1):\n",
        "        ''' Poe Dataset constructor\n",
        "\n",
        "        Args:\n",
        "            str:\n",
        "                file_path: Path to the file containing dataset\n",
        "                splt: String indicating what type of data this dataset contains\n",
        "            float:\n",
        "                split_ratio: Value between (0, 1] of what should be the ratio\n",
        "                             between training and validation set\n",
        "            int:\n",
        "                context_length: Length of the context\n",
        "                offset: An offset between the end of the context and the target\n",
        "        '''\n",
        "\n",
        "        assert split in PoeDataset.valid_split_params, f\"{split} is the wrong split type\"\n",
        "        assert split_ratio <= 1 and split_ratio > 0, f\"Split ratio value should be from range (0, 1]\"\n",
        "        assert len(text) > 0, f\"Dataset file should not be empty\"\n",
        "        assert context_length < len(text), f\"Context length should not be more than {len(text) - 1}\"\n",
        "\n",
        "        self.text = text\n",
        "        self.offset = offset\n",
        "        self.context_length = context_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = torch.tensor(self.tokenizer.encode(self.text), dtype=torch.int32, device=device)\n",
        "\n",
        "        split_idx = int(len(self.data) * split_ratio)\n",
        "        if split == \"train\":\n",
        "            self.data = self.data[:split_idx]\n",
        "        else:\n",
        "            self.data = self.data[split_idx:]\n",
        "\n",
        "    def __len__(self):\n",
        "        ''' Returns the size of the dataset\n",
        "        \n",
        "        Returns:\n",
        "            Number of possible shifts in the dataset for choosing the context chunk\n",
        "        '''\n",
        "        return len(self.data) - self.context_length - self.context_length + 1\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        ''' Returns an item of given index\n",
        "\n",
        "        Params:\n",
        "            index: Which item should be returned\n",
        "        \n",
        "        Returns:\n",
        "            Sample of given index\n",
        "        '''\n",
        "        \n",
        "        x = self.data[index: index + self.context_length]\n",
        "        y = self.data[index + self.offset: index + self.context_length + self.offset]\n",
        "\n",
        "        return x, y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fYZho5RId81o"
      },
      "outputs": [],
      "source": [
        "# Defined tokenizer class\n",
        "import torch\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "    ''' Class for character-wise tokenization'''\n",
        "\n",
        "    def __init__(self, text: str):\n",
        "        assert len(text) > 0, \"Text used for creating tokenizer cannot be empty\"\n",
        "\n",
        "        self.text = text\n",
        "        self.symbols = sorted(list(set(self.text)))\n",
        "        self.vocab_size = len(self.symbols)\n",
        "        self.stoi = { ch:i for i, ch in enumerate(self.symbols)}\n",
        "        self.itos = { i:ch for i, ch in enumerate(self.symbols)}\n",
        "\n",
        "    def encode(self, text: str) -> List:\n",
        "        ''' Encodes string to list of ints '''\n",
        "\n",
        "        return [self.stoi[ch] for ch in text]\n",
        "    \n",
        "    def decode(self, tokens: List) -> str:\n",
        "        ''' Decodes list of ints to string '''\n",
        "        \n",
        "        return ''.join([self.itos[token] for token in tokens])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x5Isk9hXQKtQ"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.dropout import Dropout\n",
        "# Simple Decoder Class definition\n",
        "### (Option) Different split, test data?\n",
        "from typing import Tuple\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SingleAttentionHead(nn.Module):\n",
        "\n",
        "    def __init__(self, head_size, config):\n",
        "        super().__init__()\n",
        "        self.n_embed = config[\"n_embed\"]\n",
        "        self.context_length = config[\"context_length\"]\n",
        "        self.dropout = config[\"dropout\"]\n",
        "\n",
        "        self.query = nn.Linear(self.n_embed, head_size, bias = False, device=device)\n",
        "        self.key = nn.Linear(self.n_embed, head_size, bias = False, device=device)\n",
        "        self.value = nn.Linear(self.n_embed, head_size, bias = False, device=device)\n",
        "        self.triangle_matrix = torch.tril(torch.ones(self.context_length, self.context_length, device=device))\n",
        "        self.head_dropout = nn.Dropout(self.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        keys = self.key(x)\n",
        "        query = self.query(x)\n",
        "\n",
        "        affinities = query @ keys.transpose(-2, -1)  # Dot product, with transposition of T and C\n",
        "        affinities *= C**(-.5)  # Normalization, to prevent softmax for skewing\n",
        "        affinities = affinities.masked_fill(self.triangle_matrix[:T, :T] == 0, float('-inf'))\n",
        "        affinities = F.softmax(affinities, dim=-1)\n",
        "        affinities = self.head_dropout(affinities)\n",
        "\n",
        "        v = self.value(x)\n",
        "        return affinities @ v\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.heads_num = config[\"att_head_num\"]\n",
        "        self.n_embed = config[\"n_embed\"]\n",
        "        self.dropout = config[\"dropout\"]\n",
        "\n",
        "        head_size = self.n_embed // self.heads_num\n",
        "        self.attention_heads = nn.ModuleList([SingleAttentionHead(head_size, config) for _ in range(self.heads_num)])\n",
        "        self.heads_projection = nn.Linear(self.n_embed, self.n_embed, device=device)\n",
        "        self.heads_dropout = nn.Dropout(self.dropout)\n",
        "        self.feed_forward = nn.Sequential(nn.Linear(self.n_embed, 4 * self.n_embed, device=device),\n",
        "                                          nn.ReLU(),\n",
        "                                          nn.Linear(4 * self.n_embed, self.n_embed, device=device),\n",
        "                                          nn.Dropout(self.dropout))\n",
        "        # '4 times n_embed' comes from the paper 'Attention is all you need' (as the whole transformer)\n",
        "        self.layer_normalization = nn.LayerNorm(self.n_embed, device=device)\n",
        "        self.layer_normalization2 = nn.LayerNorm(self.n_embed, device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_normalization(x)\n",
        "        x = x + self.heads_dropout(self.heads_projection(torch.cat([att(x) for att in self.attention_heads], dim=-1)))\n",
        "        x = self.layer_normalization2(x)\n",
        "        x = x + self.feed_forward(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class OnlyDecoder(nn.Module):\n",
        "    def __init__(self, config: dict):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = config[\"vocab_size\"]\n",
        "        self.n_embed = config[\"n_embed\"]\n",
        "        self.context_length = config[\"context_length\"]\n",
        "        self.head_num = config[\"att_head_num\"]\n",
        "        self.blocks_num = config[\"blocks_num\"]\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(self.vocab_size, self.n_embed, device=device)\n",
        "        self.pos_embedding_table = nn.Embedding(self.context_length, self.n_embed, device=device)\n",
        "        self.lin = nn.Linear(self.n_embed, self.vocab_size, device=device)\n",
        "        self.transformer_blocks = nn.Sequential(*[TransformerBlock(config) for _ in range(self.blocks_num)],\n",
        "                                                nn.LayerNorm(self.n_embed, device=device))\n",
        "        self.layer_normalization = nn.LayerNorm(self.n_embed, device=device)\n",
        "\n",
        "    def forward(self, token_idx: int, targets=None):\n",
        "        B, T = token_idx.shape\n",
        "        token_embedding = self.token_embedding_table(token_idx)\n",
        "        pos_embedding = self.pos_embedding_table(torch.arange(T, device=device))\n",
        "        x = token_embedding + pos_embedding\n",
        "        x = self.transformer_blocks(x)\n",
        "        x = self.layer_normalization(x)\n",
        "        logits = self.lin(x)\n",
        "\n",
        "        if targets is None:\n",
        "          loss = None\n",
        "        else:\n",
        "          B, T, C = logits.shape\n",
        "          logits = logits.view(B*T, C)\n",
        "          targets = targets.view(B*T)\n",
        "          targets = targets.type(torch.LongTensor).to(device)\n",
        "          loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate_new_text(self, idx, sym_limit: int) -> torch.Tensor:\n",
        "        output = []\n",
        "        for _ in range(sym_limit):\n",
        "          idx = idx if idx.size(1) <= self.context_length else idx[:, -self.context_length:]\n",
        "          logits, loss = self(idx)\n",
        "          logits = logits[:, -1, :]\n",
        "          probabilities = F.softmax(logits, dim=-1)\n",
        "          idx_next = torch.multinomial(probabilities, num_samples=1) # Take best\n",
        "          output.append(idx_next)\n",
        "          idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Wum581WusvrN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def calc_loss(model, iterations, batch_size, train_set, val_set):\n",
        "    ''' Used to evalute model by averaging on many iterations\n",
        "    \n",
        "    Args:\n",
        "        model: Evaluated model\n",
        "        iterations: Number of iterations to average through\n",
        "        batch_size: Batch size\n",
        "        train_set: Training dataset\n",
        "        val_set: Validation dataset\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with averaged losses for 'train' nad 'valid'\n",
        "    '''\n",
        "\n",
        "    split_type = [\"train\", \"valid\"]\n",
        "    outcome_losses = {}\n",
        "    model.eval()\n",
        "    for t, split in enumerate([train_set, val_set]):\n",
        "        loader = DataLoader(split, batch_size = batch_size, shuffle=True, drop_last=True)\n",
        "        loader = iter(loader)\n",
        "        losses = torch.zeros(iterations)\n",
        "        for i in range(iterations):\n",
        "            x, y = loader.__next__()\n",
        "            _, loss = model(x, y)\n",
        "            losses[i] = loss.item()\n",
        "        outcome_losses[split_type[t]] = losses.mean()\n",
        "    model.train()\n",
        "    return outcome_losses\n",
        "\n",
        "\n",
        "def train_model(model, train_set, valid_set, hyper_params: dict, device):\n",
        "    ''' Trains the model\n",
        "\n",
        "    Args:\n",
        "        model: Model to train\n",
        "        train_set: Training dataset\n",
        "        valid_set: Validation dataset\n",
        "        hyper_params: dict of hyperparameters\n",
        "    '''\n",
        "\n",
        "    lr = hyper_params[\"lr\"]\n",
        "    epochs = hyper_params[\"epochs\"]\n",
        "    batch_size = hyper_params[\"batch_size\"]\n",
        "    eval_per_epoch = hyper_params[\"eval_per_epoch\"]\n",
        "    eval_iterations = hyper_params[\"eval_iterations\"]\n",
        "    break_iter = hyper_params[\"break_iter\"]\n",
        "    if break_iter == None:\n",
        "        break_iter = len(train_set) // batch_size\n",
        "\n",
        "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "    eval_each = break_iter // eval_per_epoch\n",
        "        \n",
        "\n",
        "    for e in range(epochs):\n",
        "        for i, (x, y) in enumerate(train_dataloader):\n",
        "            if i == break_iter:\n",
        "                break\n",
        "\n",
        "            if i % eval_each == 0:\n",
        "                losses = calc_loss(model, eval_iterations, batch_size, train_set, valid_set)\n",
        "                print(f\"Epoch: [{e+1}/{epochs}] Step: [{i}/{break_iter}], train loss: {losses['train']:.4f}, val loss: {losses['valid']:.4f}\")\n",
        "            \n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, loss = model(x, y)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1nwQWyQqNCu",
        "outputId": "2dcae3c5-5d6d-43bd-a7c2-840100a73526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [1/2] Step: [0/48603], train loss: 11.6390, val loss: 11.6448\n",
            "Epoch: [1/2] Step: [4860/48603], train loss: 7.0154, val loss: 7.0475\n",
            "Epoch: [1/2] Step: [9720/48603], train loss: 6.8036, val loss: 6.8972\n",
            "Epoch: [1/2] Step: [14580/48603], train loss: 6.6562, val loss: 6.7863\n",
            "Epoch: [1/2] Step: [19440/48603], train loss: 6.5063, val loss: 6.7199\n",
            "Epoch: [1/2] Step: [24300/48603], train loss: 6.3745, val loss: 6.6629\n",
            "Epoch: [1/2] Step: [29160/48603], train loss: 6.2774, val loss: 6.5777\n",
            "Epoch: [1/2] Step: [34020/48603], train loss: 6.2041, val loss: 6.5671\n",
            "Epoch: [1/2] Step: [38880/48603], train loss: 6.1158, val loss: 6.5030\n",
            "Epoch: [1/2] Step: [43740/48603], train loss: 6.0360, val loss: 6.4572\n",
            "Epoch: [1/2] Step: [48600/48603], train loss: 5.9720, val loss: 6.4426\n",
            "Epoch: [2/2] Step: [0/48603], train loss: 5.9778, val loss: 6.4123\n",
            "Epoch: [2/2] Step: [4860/48603], train loss: 5.9019, val loss: 6.3775\n",
            "Epoch: [2/2] Step: [9720/48603], train loss: 5.8399, val loss: 6.3521\n",
            "Epoch: [2/2] Step: [14580/48603], train loss: 5.7614, val loss: 6.3599\n",
            "Epoch: [2/2] Step: [19440/48603], train loss: 5.7131, val loss: 6.3042\n",
            "Epoch: [2/2] Step: [24300/48603], train loss: 5.6500, val loss: 6.3093\n",
            "Epoch: [2/2] Step: [29160/48603], train loss: 5.5955, val loss: 6.2911\n",
            "Epoch: [2/2] Step: [34020/48603], train loss: 5.5546, val loss: 6.2906\n",
            "Epoch: [2/2] Step: [38880/48603], train loss: 5.5029, val loss: 6.2439\n",
            "Epoch: [2/2] Step: [43740/48603], train loss: 5.4450, val loss: 6.2370\n",
            "Epoch: [2/2] Step: [48600/48603], train loss: 5.4144, val loss: 6.2293\n"
          ]
        }
      ],
      "source": [
        "# Setting up the dataset parameters\n",
        "### (Option 1) We can use different tokenizer, like SentencePiece\n",
        "### (Option 2) We can build our own tokenizer, using huggingface library\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"poe_data.txt\"\n",
        "\n",
        "# Reading file, preparing tokenizer\n",
        "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "# Setting up dataset\n",
        "split_ratio = 0.9\n",
        "context_length = 256\n",
        "offset = 1  # I am wondering what would be the results for 2, for example\n",
        "custom_tokenizer = False\n",
        "\n",
        "if custom_tokenizer:\n",
        "    tokenizer = Tokenizer(text)\n",
        "    vocab_size = tokenizer.vocab_size\n",
        "else:\n",
        "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    vocab_size = tokenizer.n_vocab\n",
        "\n",
        "# Setting up model (!!! head_size should be n_embed // head_num)\n",
        "net_config = { \"vocab_size\": vocab_size,\n",
        "               \"n_embed\": 32,\n",
        "               \"context_length\": context_length,\n",
        "               \"att_head_num\": 4,\n",
        "               \"blocks_num\": 3,\n",
        "               \"dropout\": .2}\n",
        "\n",
        "symbols_limit = 50\n",
        "model = OnlyDecoder(net_config)\n",
        "model.to(device)\n",
        "\n",
        "# Training parameters\n",
        "hypers = {\n",
        "    \"lr\": .3e-4,\n",
        "    \"epochs\": 2,\n",
        "    \"batch_size\": 8,\n",
        "    \"eval_per_epoch\": 10,\n",
        "    \"eval_iterations\": 200,\n",
        "    \"break_iter\": None\n",
        "}\n",
        "\n",
        "# Training\n",
        "train_set = PoeDataset(text, 'train', split_ratio, context_length, tokenizer, offset=offset)\n",
        "val_set = PoeDataset(text, 'valid', split_ratio, context_length, tokenizer, offset=offset)\n",
        "\n",
        "train_model(model, train_set, val_set, hypers, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4-RcZ2YpkNMV"
      },
      "outputs": [],
      "source": [
        "save_path = 'state.pt'\n",
        "torch.save(model.state_dict(), save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGrCGZ2W1c6g",
        "outputId": "6bb08446-1e82-4003-ea89-23e1dd7e022f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "—hung breadth to my beloved:—ithum!—hisuation can be considered with his explanations.   “Oiluded been too say dat left. In each time known for human diminutive facacy of the besides in the immediate comensance, I had been attributed ago (for indère. “shot—thereical neglected did he called into it? I have a thing When and “The good trance-ocityings.   Meumies of guggestion.”   “Independ have reached me!”! do the escape!” overs roundless fellow, and tried in some a young from the same portion to me the correctok. “unlessaries,” That, King, and I youasora, madis; all ‘Be nor emerged—that it dust, boldly. Oaphise in a “perhaps, will sustain the sleeve than his drawing, “van proverbiter rather vast coatieur’é and origin, moreover indul insin, as the balloon were now die. This end, will\n"
          ]
        }
      ],
      "source": [
        "test_text_length = 200\n",
        "\n",
        "# Test it\n",
        "starter = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(tokenizer.decode([t.item() for t in model.generate_new_text(starter, test_text_length)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DMEZ9ZXxkbUT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
