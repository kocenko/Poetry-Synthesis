{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Poetry Notebook\n",
        "\n",
        "In this notebook we will be implementing GPT to generate text based on the work of Edgar Allan Poe."
      ],
      "metadata": {
        "id": "cqUrnIpoqAHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing dependencies\n",
        "!pip install tiktoken\n",
        "!pip install torch\n",
        "\n",
        "# Downloading dataset from the GitHub\n",
        "!wget https://raw.githubusercontent.com/kocenko/Poetry-Synthesis/dev/data/poe_data.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0d5dI4LKXBp",
        "outputId": "8e4313f2-d8b1-4003-941e-69d04bb260d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "--2023-05-16 19:52:05--  https://raw.githubusercontent.com/kocenko/Poetry-Synthesis/dev/data/poe_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1930488 (1.8M) [text/plain]\n",
            "Saving to: ‘poe_data.txt’\n",
            "\n",
            "poe_data.txt        100%[===================>]   1.84M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-05-16 19:52:05 (47.9 MB/s) - ‘poe_data.txt’ saved [1930488/1930488]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Essential imports\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "PqtdnLBxN3sQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "\n",
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "zLSR7xdlPQaN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class definition\n",
        "### (Option) We can use different data to train it on\n",
        "### (Option) What if the context affects not the following\n",
        "###          but the one after the following token? (bigger offset)\n",
        "\n",
        "class PoeDataset(Dataset):\n",
        "    valid_split_params = [\"train\", \"valid\"]\n",
        "\n",
        "    def __init__(self, text: str, split: str, split_ratio: float, context_length: int, tokenizer, offset: int = 1):\n",
        "        ''' Poe Dataset constructor\n",
        "\n",
        "        Args:\n",
        "            str:\n",
        "                file_path: Path to the file containing dataset\n",
        "                splt: String indicating what type of data this dataset contains\n",
        "            float:\n",
        "                split_ratio: Value between (0, 1] of what should be the ratio\n",
        "                             between training and validation set\n",
        "            int:\n",
        "                context_length: Length of the context\n",
        "                offset: An offset between the end of the context and the target\n",
        "        '''\n",
        "\n",
        "        assert split in PoeDataset.valid_split_params, f\"{split} is the wrong split type\"\n",
        "        assert split_ratio <= 1 and split_ratio > 0, f\"Split ratio value should be from range (0, 1]\"\n",
        "        assert len(text) > 0, f\"Dataset file should not be empty\"\n",
        "        assert context_length < len(text), f\"Context length should not be more than {len(text) - 1}\"\n",
        "\n",
        "        self.text = text\n",
        "        self.offset = offset\n",
        "        self.context_length = context_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = torch.tensor(self.tokenizer.encode(self.text), dtype=torch.int32, device=device)\n",
        "\n",
        "        split_idx = int(len(self.data) * split_ratio)\n",
        "        if split == \"train\":\n",
        "            self.data = self.data[:split_idx]\n",
        "        else:\n",
        "            self.data = self.data[split_idx:]\n",
        "\n",
        "    def __len__(self):\n",
        "        ''' Returns the size of the dataset\n",
        "        \n",
        "        Returns:\n",
        "            Number of possible shifts in the dataset for choosing the context chunk\n",
        "        '''\n",
        "        return len(self.data) - self.context_length - self.context_length + 1\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        ''' Returns an item of given index\n",
        "\n",
        "        Params:\n",
        "            index: Which item should be returned\n",
        "        \n",
        "        Returns:\n",
        "            Sample of given index\n",
        "        '''\n",
        "        \n",
        "        x = self.data[index: index + self.context_length]\n",
        "        y = self.data[index + self.offset: index + self.context_length + self.offset]\n",
        "\n",
        "        return x, y\n",
        "\n"
      ],
      "metadata": {
        "id": "4K9Stu5Uy3Ym"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defined tokenizer class\n",
        "import torch\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class Tokenizer:\n",
        "    ''' Class for character-wise tokenization'''\n",
        "\n",
        "    def __init__(self, text: str):\n",
        "        assert len(text) > 0, \"Text used for creating tokenizer cannot be empty\"\n",
        "\n",
        "        self.text = text\n",
        "        self.symbols = sorted(list(set(self.text)))\n",
        "        self.vocab_size = len(self.symbols)\n",
        "        self.stoi = { ch:i for i, ch in enumerate(self.symbols)}\n",
        "        self.itos = { i:ch for i, ch in enumerate(self.symbols)}\n",
        "\n",
        "    def encode(self, text: str) -> List:\n",
        "        ''' Encodes string to list of ints '''\n",
        "\n",
        "        return [self.stoi[ch] for ch in text]\n",
        "    \n",
        "    def decode(self, tokens: List) -> str:\n",
        "        ''' Decodes list of ints to string '''\n",
        "        \n",
        "        return ''.join([self.itos[token] for token in tokens])\n"
      ],
      "metadata": {
        "id": "fYZho5RId81o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Decoder Class definition\n",
        "### (Option) Different split, test data?\n",
        "from typing import Tuple\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SingleAttentionHead(nn.Module):\n",
        "\n",
        "    def __init__(self, head_size, config):\n",
        "        super().__init__()\n",
        "        self.n_embed = config[\"n_embed\"]\n",
        "        self.context_length = config[\"context_length\"]\n",
        "\n",
        "        self.query = nn.Linear(self.n_embed, head_size, bias = False, device=device)\n",
        "        self.key = nn.Linear(self.n_embed, head_size, bias = False, device=device)\n",
        "        self.value = nn.Linear(self.n_embed, head_size, bias = False, device=device)\n",
        "        self.triangle_matrix = torch.tril(torch.ones(self.context_length, self.context_length, device=device))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        keys = self.key(x)\n",
        "        query = self.query(x)\n",
        "\n",
        "        affinities = query @ keys.transpose(-2, -1)  # Dot product, with transposition of T and C\n",
        "        affinities *= C**(-.5)  # Normalization, to prevent softmax for skewing\n",
        "        affinities = affinities.masked_fill(self.triangle_matrix[:T, :T] == 0, float('-inf'))\n",
        "        affinities = F.softmax(affinities, dim=-1)\n",
        "\n",
        "        v = self.value(x)\n",
        "        return affinities @ v\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.heads_num = config[\"att_head_num\"]\n",
        "        self.n_embed = config[\"n_embed\"]\n",
        "\n",
        "        head_size = self.n_embed // self.heads_num\n",
        "        self.attention_heads = nn.ModuleList([SingleAttentionHead(head_size, config) for _ in range(self.heads_num)])\n",
        "        self.heads_projection = nn.Linear(self.n_embed, self.n_embed, device=device)\n",
        "        self.feed_forward = nn.Sequential(nn.Linear(self.n_embed, 4 * self.n_embed, device=device),\n",
        "                                          nn.ReLU(),\n",
        "                                          nn.Linear(4 * self.n_embed, self.n_embed, device=device))\n",
        "        # '4 times n_embed' comes from the paper 'Attention is all you need' (as the whole transformer)\n",
        "        self.layer_normalization = nn.LayerNorm(self.n_embed, device=device)\n",
        "        self.layer_normalization2 = nn.LayerNorm(self.n_embed, device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_normalization(x)\n",
        "        x = x + self.heads_projection(torch.cat([att(x) for att in self.attention_heads], dim=-1))\n",
        "        x = self.layer_normalization2(x)\n",
        "        x = x + self.feed_forward(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class OnlyDecoder(nn.Module):\n",
        "    def __init__(self, config: dict):\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = config[\"vocab_size\"]\n",
        "        self.n_embed = config[\"n_embed\"]\n",
        "        self.context_length = config[\"context_length\"]\n",
        "        self.head_num = config[\"att_head_num\"]\n",
        "        self.blocks_num = config[\"blocks_num\"]\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(self.vocab_size, self.n_embed, device=device)\n",
        "        self.pos_embedding_table = nn.Embedding(self.context_length, self.n_embed, device=device)\n",
        "        self.lin = nn.Linear(self.n_embed, self.vocab_size, device=device)\n",
        "        self.transformer_blocks = nn.Sequential(*[TransformerBlock(config) for _ in range(self.blocks_num)],\n",
        "                                                nn.LayerNorm(self.n_embed, device=device))\n",
        "        self.layer_normalization = nn.LayerNorm(self.n_embed, device=device)\n",
        "\n",
        "    def forward(self, token_idx: int, targets=None):\n",
        "        B, T = token_idx.shape\n",
        "        token_embedding = self.token_embedding_table(token_idx)\n",
        "        pos_embedding = self.pos_embedding_table(torch.arange(T, device=device))\n",
        "        x = token_embedding + pos_embedding\n",
        "        x = self.transformer_blocks(x)\n",
        "        x = self.layer_normalization(x)\n",
        "        logits = self.lin(x)\n",
        "\n",
        "        if targets is None:\n",
        "          loss = None\n",
        "        else:\n",
        "          B, T, C = logits.shape\n",
        "          logits = logits.view(B*T, C)\n",
        "          targets = targets.view(B*T)\n",
        "          targets = targets.type(torch.LongTensor).to(device)\n",
        "          loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate_new_text(self, idx, sym_limit: int) -> torch.Tensor:\n",
        "        output = []\n",
        "        for _ in range(sym_limit):\n",
        "          idx = idx if idx.size(1) <= self.context_length else idx[:, -self.context_length:]\n",
        "          logits, loss = self(idx)\n",
        "          logits = logits[:, -1, :]\n",
        "          probabilities = F.softmax(logits, dim=-1)\n",
        "          idx_next = torch.multinomial(probabilities, num_samples=1) # Take best\n",
        "          output.append(idx_next)\n",
        "          idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "x5Isk9hXQKtQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def calc_loss(model, iterations, batch_size, train_set, val_set):\n",
        "    ''' Used to evalute model by averaging on many iterations\n",
        "    \n",
        "    Args:\n",
        "        model: Evaluated model\n",
        "        iterations: Number of iterations to average through\n",
        "        batch_size: Batch size\n",
        "        train_set: Training dataset\n",
        "        val_set: Validation dataset\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with averaged losses for 'train' nad 'valid'\n",
        "    '''\n",
        "\n",
        "    split_type = [\"train\", \"valid\"]\n",
        "    outcome_losses = {}\n",
        "    model.eval()\n",
        "    for t, split in enumerate([train_set, val_set]):\n",
        "        loader = DataLoader(split, batch_size = batch_size, shuffle=True, drop_last=True)\n",
        "        loader = iter(loader)\n",
        "        losses = torch.zeros(iterations)\n",
        "        for i in range(iterations):\n",
        "            x, y = loader.__next__()\n",
        "            _, loss = model(x, y)\n",
        "            losses[i] = loss.item()\n",
        "        outcome_losses[split_type[t]] = losses.mean()\n",
        "    model.train()\n",
        "    return outcome_losses\n",
        "\n",
        "\n",
        "def train_model(model, train_set, valid_set, hyper_params: dict, device):\n",
        "    ''' Trains the model\n",
        "\n",
        "    Args:\n",
        "        model: Model to train\n",
        "        train_set: Training dataset\n",
        "        valid_set: Validation dataset\n",
        "        hyper_params: dict of hyperparameters\n",
        "    '''\n",
        "\n",
        "    lr = hyper_params[\"lr\"]\n",
        "    epochs = hyper_params[\"epochs\"]\n",
        "    batch_size = hyper_params[\"batch_size\"]\n",
        "    eval_each = hyper_params[\"eval_each\"]\n",
        "    eval_iterations = hyper_params[\"eval_iterations\"]\n",
        "    break_iter = hyper_params[\"break_iter\"]\n",
        "\n",
        "    train_dataloader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "\n",
        "    for e in range(epochs):\n",
        "        for i, (x, y) in enumerate(train_dataloader):\n",
        "            if i == break_iter:\n",
        "                break\n",
        "\n",
        "            if i % eval_each == 0:\n",
        "                losses = calc_loss(model, eval_iterations, batch_size, train_set, valid_set)\n",
        "                print(f\"Epoch: {e} Step: {i}, train loss: {losses['train']:.4f}, val loss: {losses['valid']:.4f}\")\n",
        "            \n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, loss = model(x, y)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n"
      ],
      "metadata": {
        "id": "Wum581WusvrN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the dataset parameters\n",
        "### (Option 1) We can use different tokenizer, like SentencePiece\n",
        "### (Option 2) We can build our own tokenizer, using huggingface library\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"poe_data.txt\"\n",
        "\n",
        "# Reading file, preparing tokenizer\n",
        "with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "\n",
        "# Setting up dataset\n",
        "split_ratio = 0.85\n",
        "context_length = 8\n",
        "offset = 1  # I am wondering what would be the results for 2, for example\n",
        "custom_tokenizer = False\n",
        "\n",
        "if custom_tokenizer:\n",
        "    tokenizer = Tokenizer(text)\n",
        "    vocab_size = tokenizer.vocab_size\n",
        "else:\n",
        "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    vocab_size = tokenizer.n_vocab\n",
        "\n",
        "# Setting up model (!!! head_size should be n_embed // head_num)\n",
        "net_config = { \"vocab_size\": vocab_size,\n",
        "               \"n_embed\": 32,\n",
        "               \"context_length\": context_length,\n",
        "               \"att_head_num\": 4,\n",
        "               \"blocks_num\": 3}\n",
        "\n",
        "symbols_limit = 50\n",
        "model = OnlyDecoder(net_config)\n",
        "model.to(device)\n",
        "\n",
        "# Training parameters\n",
        "hypers = {\n",
        "    \"lr\": .3e-4,\n",
        "    \"epochs\": 5,\n",
        "    \"batch_size\": 32,\n",
        "    \"eval_each\": 200,\n",
        "    \"eval_iterations\": 200,\n",
        "    \"break_iter\": 10000\n",
        "}\n",
        "\n",
        "# Training\n",
        "train_set = PoeDataset(text, 'train', split_ratio, context_length, tokenizer, offset=offset)\n",
        "val_set = PoeDataset(text, 'valid', split_ratio, context_length, tokenizer, offset=offset)\n",
        "\n",
        "train_dataloader = DataLoader(train_set, batch_size=4, shuffle=True, drop_last=True)\n",
        "train_model(model, train_set, val_set, hypers, device=device)\n",
        "\n",
        "# Test it\n",
        "starter = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(tokenizer.decode(model.generate_new_text(starter, 200)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1nwQWyQqNCu",
        "outputId": "ff79314c-bee6-4584-a6ca-996c7a888f6f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 Step: 0, train loss: 11.6868, val loss: 11.6843\n",
            "Epoch: 0 Step: 200, train loss: 11.3956, val loss: 11.3853\n",
            "Epoch: 0 Step: 400, train loss: 11.0098, val loss: 11.0030\n",
            "Epoch: 0 Step: 600, train loss: 10.6879, val loss: 10.6785\n",
            "Epoch: 0 Step: 800, train loss: 10.3888, val loss: 10.3782\n",
            "Epoch: 0 Step: 1000, train loss: 10.1026, val loss: 10.1024\n",
            "Epoch: 0 Step: 1200, train loss: 9.8157, val loss: 9.8351\n",
            "Epoch: 0 Step: 1400, train loss: 9.5640, val loss: 9.5704\n",
            "Epoch: 0 Step: 1600, train loss: 9.3126, val loss: 9.3289\n",
            "Epoch: 0 Step: 1800, train loss: 9.0762, val loss: 9.0991\n",
            "Epoch: 0 Step: 2000, train loss: 8.8596, val loss: 8.8788\n",
            "Epoch: 0 Step: 2200, train loss: 8.6590, val loss: 8.6775\n",
            "Epoch: 0 Step: 2400, train loss: 8.4616, val loss: 8.4833\n",
            "Epoch: 0 Step: 2600, train loss: 8.2840, val loss: 8.2980\n",
            "Epoch: 0 Step: 2800, train loss: 8.1156, val loss: 8.1373\n",
            "Epoch: 0 Step: 3000, train loss: 7.9585, val loss: 8.0008\n",
            "Epoch: 0 Step: 3200, train loss: 7.8210, val loss: 7.8443\n",
            "Epoch: 0 Step: 3400, train loss: 7.7006, val loss: 7.7451\n",
            "Epoch: 0 Step: 3600, train loss: 7.5954, val loss: 7.6475\n",
            "Epoch: 0 Step: 3800, train loss: 7.4872, val loss: 7.5492\n",
            "Epoch: 0 Step: 4000, train loss: 7.3980, val loss: 7.4585\n",
            "Epoch: 0 Step: 4200, train loss: 7.3427, val loss: 7.3769\n",
            "Epoch: 0 Step: 4400, train loss: 7.2807, val loss: 7.3180\n",
            "Epoch: 0 Step: 4600, train loss: 7.2315, val loss: 7.2804\n",
            "Epoch: 0 Step: 4800, train loss: 7.1884, val loss: 7.2450\n",
            "Epoch: 0 Step: 5000, train loss: 7.1379, val loss: 7.2228\n",
            "Epoch: 0 Step: 5200, train loss: 7.1291, val loss: 7.1803\n",
            "Epoch: 0 Step: 5400, train loss: 7.1010, val loss: 7.1576\n",
            "Epoch: 0 Step: 5600, train loss: 7.0892, val loss: 7.1426\n",
            "Epoch: 0 Step: 5800, train loss: 7.0807, val loss: 7.1299\n",
            "Epoch: 0 Step: 6000, train loss: 7.0465, val loss: 7.1110\n",
            "Epoch: 0 Step: 6200, train loss: 7.0458, val loss: 7.1172\n",
            "Epoch: 0 Step: 6400, train loss: 7.0446, val loss: 7.1323\n",
            "Epoch: 0 Step: 6600, train loss: 7.0477, val loss: 7.0806\n",
            "Epoch: 0 Step: 6800, train loss: 7.0150, val loss: 7.0798\n",
            "Epoch: 0 Step: 7000, train loss: 6.9970, val loss: 7.0653\n",
            "Epoch: 0 Step: 7200, train loss: 6.9881, val loss: 7.0671\n",
            "Epoch: 0 Step: 7400, train loss: 6.9892, val loss: 7.0778\n",
            "Epoch: 0 Step: 7600, train loss: 6.9784, val loss: 7.0414\n",
            "Epoch: 0 Step: 7800, train loss: 6.9569, val loss: 7.0506\n",
            "Epoch: 0 Step: 8000, train loss: 6.9855, val loss: 7.0745\n",
            "Epoch: 0 Step: 8200, train loss: 6.9521, val loss: 7.0441\n",
            "Epoch: 0 Step: 8400, train loss: 6.9459, val loss: 7.0422\n",
            "Epoch: 0 Step: 8600, train loss: 6.9478, val loss: 7.0233\n",
            "Epoch: 0 Step: 8800, train loss: 6.9181, val loss: 7.0822\n",
            "Epoch: 0 Step: 9000, train loss: 6.9378, val loss: 7.0564\n",
            "Epoch: 0 Step: 9200, train loss: 6.9351, val loss: 7.0266\n",
            "Epoch: 0 Step: 9400, train loss: 6.9422, val loss: 7.0166\n",
            "Epoch: 0 Step: 9600, train loss: 6.8989, val loss: 7.0209\n",
            "Epoch: 0 Step: 9800, train loss: 6.9141, val loss: 7.0071\n",
            "Epoch: 1 Step: 0, train loss: 6.9249, val loss: 6.9914\n",
            "Epoch: 1 Step: 200, train loss: 6.9075, val loss: 7.0111\n",
            "Epoch: 1 Step: 400, train loss: 6.8991, val loss: 7.0220\n",
            "Epoch: 1 Step: 600, train loss: 6.8700, val loss: 7.0031\n",
            "Epoch: 1 Step: 800, train loss: 6.8951, val loss: 6.9977\n",
            "Epoch: 1 Step: 1000, train loss: 6.8903, val loss: 7.0145\n",
            "Epoch: 1 Step: 1200, train loss: 6.8893, val loss: 6.9932\n",
            "Epoch: 1 Step: 1400, train loss: 6.8797, val loss: 6.9681\n",
            "Epoch: 1 Step: 1600, train loss: 6.8798, val loss: 7.0012\n",
            "Epoch: 1 Step: 1800, train loss: 6.8668, val loss: 7.0071\n",
            "Epoch: 1 Step: 2000, train loss: 6.8779, val loss: 6.9987\n",
            "Epoch: 1 Step: 2200, train loss: 6.8616, val loss: 6.9914\n",
            "Epoch: 1 Step: 2400, train loss: 6.8643, val loss: 6.9851\n",
            "Epoch: 1 Step: 2600, train loss: 6.8386, val loss: 6.9889\n",
            "Epoch: 1 Step: 2800, train loss: 6.8362, val loss: 6.9668\n",
            "Epoch: 1 Step: 3000, train loss: 6.8344, val loss: 6.9920\n",
            "Epoch: 1 Step: 3200, train loss: 6.8284, val loss: 6.9543\n",
            "Epoch: 1 Step: 3400, train loss: 6.8374, val loss: 6.9704\n",
            "Epoch: 1 Step: 3600, train loss: 6.8339, val loss: 6.9747\n",
            "Epoch: 1 Step: 3800, train loss: 6.8245, val loss: 6.9784\n",
            "Epoch: 1 Step: 4000, train loss: 6.8255, val loss: 6.9569\n",
            "Epoch: 1 Step: 4200, train loss: 6.8019, val loss: 6.9958\n",
            "Epoch: 1 Step: 4400, train loss: 6.8294, val loss: 6.9621\n",
            "Epoch: 1 Step: 4600, train loss: 6.7965, val loss: 6.9656\n",
            "Epoch: 1 Step: 4800, train loss: 6.7816, val loss: 6.9583\n",
            "Epoch: 1 Step: 5000, train loss: 6.7823, val loss: 6.9624\n",
            "Epoch: 1 Step: 5200, train loss: 6.7849, val loss: 6.9619\n",
            "Epoch: 1 Step: 5400, train loss: 6.7760, val loss: 6.9626\n",
            "Epoch: 1 Step: 5600, train loss: 6.7861, val loss: 6.9345\n",
            "Epoch: 1 Step: 5800, train loss: 6.7813, val loss: 6.9558\n",
            "Epoch: 1 Step: 6000, train loss: 6.7982, val loss: 6.9510\n",
            "Epoch: 1 Step: 6200, train loss: 6.7905, val loss: 6.9699\n",
            "Epoch: 1 Step: 6400, train loss: 6.7841, val loss: 6.9316\n",
            "Epoch: 1 Step: 6600, train loss: 6.7587, val loss: 6.9570\n",
            "Epoch: 1 Step: 6800, train loss: 6.7500, val loss: 6.9543\n",
            "Epoch: 1 Step: 7000, train loss: 6.7673, val loss: 6.9232\n",
            "Epoch: 1 Step: 7200, train loss: 6.7339, val loss: 6.9416\n",
            "Epoch: 1 Step: 7400, train loss: 6.7516, val loss: 6.9157\n",
            "Epoch: 1 Step: 7600, train loss: 6.7381, val loss: 6.9466\n",
            "Epoch: 1 Step: 7800, train loss: 6.7341, val loss: 6.9178\n",
            "Epoch: 1 Step: 8000, train loss: 6.7347, val loss: 6.9223\n",
            "Epoch: 1 Step: 8200, train loss: 6.7137, val loss: 6.9346\n",
            "Epoch: 1 Step: 8400, train loss: 6.7348, val loss: 6.9442\n",
            "Epoch: 1 Step: 8600, train loss: 6.7078, val loss: 6.9287\n",
            "Epoch: 1 Step: 8800, train loss: 6.7181, val loss: 6.9179\n",
            "Epoch: 1 Step: 9000, train loss: 6.7134, val loss: 6.8988\n",
            "Epoch: 1 Step: 9200, train loss: 6.7096, val loss: 6.9185\n",
            "Epoch: 1 Step: 9400, train loss: 6.6992, val loss: 6.9241\n",
            "Epoch: 1 Step: 9600, train loss: 6.6905, val loss: 6.9112\n",
            "Epoch: 1 Step: 9800, train loss: 6.6909, val loss: 6.9214\n",
            "Epoch: 2 Step: 0, train loss: 6.6959, val loss: 6.8713\n",
            "Epoch: 2 Step: 200, train loss: 6.6971, val loss: 6.8859\n",
            "Epoch: 2 Step: 400, train loss: 6.6759, val loss: 6.8787\n",
            "Epoch: 2 Step: 600, train loss: 6.6724, val loss: 6.8884\n",
            "Epoch: 2 Step: 800, train loss: 6.6816, val loss: 6.8905\n",
            "Epoch: 2 Step: 1000, train loss: 6.6709, val loss: 6.9093\n",
            "Epoch: 2 Step: 1200, train loss: 6.6651, val loss: 6.8924\n",
            "Epoch: 2 Step: 1400, train loss: 6.6589, val loss: 6.8880\n",
            "Epoch: 2 Step: 1600, train loss: 6.6424, val loss: 6.8821\n",
            "Epoch: 2 Step: 1800, train loss: 6.6564, val loss: 6.8919\n",
            "Epoch: 2 Step: 2000, train loss: 6.6293, val loss: 6.8709\n",
            "Epoch: 2 Step: 2200, train loss: 6.6552, val loss: 6.8940\n",
            "Epoch: 2 Step: 2400, train loss: 6.6430, val loss: 6.8855\n",
            "Epoch: 2 Step: 2600, train loss: 6.6068, val loss: 6.8686\n",
            "Epoch: 2 Step: 2800, train loss: 6.6409, val loss: 6.8796\n",
            "Epoch: 2 Step: 3000, train loss: 6.6167, val loss: 6.8679\n",
            "Epoch: 2 Step: 3200, train loss: 6.6392, val loss: 6.8531\n",
            "Epoch: 2 Step: 3400, train loss: 6.6037, val loss: 6.8598\n",
            "Epoch: 2 Step: 3600, train loss: 6.5929, val loss: 6.8681\n",
            "Epoch: 2 Step: 3800, train loss: 6.6074, val loss: 6.8764\n",
            "Epoch: 2 Step: 4000, train loss: 6.5856, val loss: 6.8398\n",
            "Epoch: 2 Step: 4200, train loss: 6.5980, val loss: 6.8613\n",
            "Epoch: 2 Step: 4400, train loss: 6.6132, val loss: 6.8485\n",
            "Epoch: 2 Step: 4600, train loss: 6.5876, val loss: 6.8101\n",
            "Epoch: 2 Step: 4800, train loss: 6.6101, val loss: 6.8239\n",
            "Epoch: 2 Step: 5000, train loss: 6.5877, val loss: 6.8438\n",
            "Epoch: 2 Step: 5200, train loss: 6.5493, val loss: 6.8326\n",
            "Epoch: 2 Step: 5400, train loss: 6.5813, val loss: 6.8180\n",
            "Epoch: 2 Step: 5600, train loss: 6.5713, val loss: 6.8372\n",
            "Epoch: 2 Step: 5800, train loss: 6.5603, val loss: 6.8060\n",
            "Epoch: 2 Step: 6000, train loss: 6.5554, val loss: 6.8522\n",
            "Epoch: 2 Step: 6200, train loss: 6.5683, val loss: 6.8157\n",
            "Epoch: 2 Step: 6400, train loss: 6.5658, val loss: 6.7914\n",
            "Epoch: 2 Step: 6600, train loss: 6.5422, val loss: 6.7927\n",
            "Epoch: 2 Step: 6800, train loss: 6.5734, val loss: 6.8551\n",
            "Epoch: 2 Step: 7000, train loss: 6.5621, val loss: 6.8038\n",
            "Epoch: 2 Step: 7200, train loss: 6.5329, val loss: 6.8045\n",
            "Epoch: 2 Step: 7400, train loss: 6.5477, val loss: 6.8416\n",
            "Epoch: 2 Step: 7600, train loss: 6.5379, val loss: 6.8248\n",
            "Epoch: 2 Step: 7800, train loss: 6.5394, val loss: 6.7993\n",
            "Epoch: 2 Step: 8000, train loss: 6.5263, val loss: 6.7734\n",
            "Epoch: 2 Step: 8200, train loss: 6.5167, val loss: 6.8127\n",
            "Epoch: 2 Step: 8400, train loss: 6.5234, val loss: 6.7657\n",
            "Epoch: 2 Step: 8600, train loss: 6.5004, val loss: 6.7827\n",
            "Epoch: 2 Step: 8800, train loss: 6.4930, val loss: 6.7769\n",
            "Epoch: 2 Step: 9000, train loss: 6.4996, val loss: 6.7878\n",
            "Epoch: 2 Step: 9200, train loss: 6.5302, val loss: 6.8009\n",
            "Epoch: 2 Step: 9400, train loss: 6.4942, val loss: 6.7922\n",
            "Epoch: 2 Step: 9600, train loss: 6.4901, val loss: 6.7774\n",
            "Epoch: 2 Step: 9800, train loss: 6.4857, val loss: 6.7896\n",
            "Epoch: 3 Step: 0, train loss: 6.4701, val loss: 6.7788\n",
            "Epoch: 3 Step: 200, train loss: 6.4803, val loss: 6.7670\n",
            "Epoch: 3 Step: 400, train loss: 6.4871, val loss: 6.7539\n",
            "Epoch: 3 Step: 600, train loss: 6.4684, val loss: 6.7682\n",
            "Epoch: 3 Step: 800, train loss: 6.4717, val loss: 6.7730\n",
            "Epoch: 3 Step: 1000, train loss: 6.4782, val loss: 6.7880\n",
            "Epoch: 3 Step: 1200, train loss: 6.4785, val loss: 6.7604\n",
            "Epoch: 3 Step: 1400, train loss: 6.4545, val loss: 6.7366\n",
            "Epoch: 3 Step: 1600, train loss: 6.4408, val loss: 6.7465\n",
            "Epoch: 3 Step: 1800, train loss: 6.4784, val loss: 6.7560\n",
            "Epoch: 3 Step: 2000, train loss: 6.4470, val loss: 6.7544\n",
            "Epoch: 3 Step: 2200, train loss: 6.4317, val loss: 6.7546\n",
            "Epoch: 3 Step: 2400, train loss: 6.4594, val loss: 6.7373\n",
            "Epoch: 3 Step: 2600, train loss: 6.4450, val loss: 6.7358\n",
            "Epoch: 3 Step: 2800, train loss: 6.4350, val loss: 6.7449\n",
            "Epoch: 3 Step: 3000, train loss: 6.4291, val loss: 6.7544\n",
            "Epoch: 3 Step: 3200, train loss: 6.4277, val loss: 6.7419\n",
            "Epoch: 3 Step: 3400, train loss: 6.4073, val loss: 6.7341\n",
            "Epoch: 3 Step: 3600, train loss: 6.4249, val loss: 6.7010\n",
            "Epoch: 3 Step: 3800, train loss: 6.4159, val loss: 6.7126\n",
            "Epoch: 3 Step: 4000, train loss: 6.4051, val loss: 6.7094\n",
            "Epoch: 3 Step: 4200, train loss: 6.3933, val loss: 6.7585\n",
            "Epoch: 3 Step: 4400, train loss: 6.4101, val loss: 6.6944\n",
            "Epoch: 3 Step: 4600, train loss: 6.4046, val loss: 6.7313\n",
            "Epoch: 3 Step: 4800, train loss: 6.4231, val loss: 6.7020\n",
            "Epoch: 3 Step: 5000, train loss: 6.4070, val loss: 6.7101\n",
            "Epoch: 3 Step: 5200, train loss: 6.3749, val loss: 6.6687\n",
            "Epoch: 3 Step: 5400, train loss: 6.4034, val loss: 6.7150\n",
            "Epoch: 3 Step: 5600, train loss: 6.3901, val loss: 6.7019\n",
            "Epoch: 3 Step: 5800, train loss: 6.3737, val loss: 6.7331\n",
            "Epoch: 3 Step: 6000, train loss: 6.3784, val loss: 6.6937\n",
            "Epoch: 3 Step: 6200, train loss: 6.3906, val loss: 6.7148\n",
            "Epoch: 3 Step: 6400, train loss: 6.3585, val loss: 6.7484\n",
            "Epoch: 3 Step: 6600, train loss: 6.3740, val loss: 6.6757\n",
            "Epoch: 3 Step: 6800, train loss: 6.3331, val loss: 6.7038\n",
            "Epoch: 3 Step: 7000, train loss: 6.3615, val loss: 6.7072\n",
            "Epoch: 3 Step: 7200, train loss: 6.3611, val loss: 6.6897\n",
            "Epoch: 3 Step: 7400, train loss: 6.3507, val loss: 6.6931\n",
            "Epoch: 3 Step: 7600, train loss: 6.3389, val loss: 6.6932\n",
            "Epoch: 3 Step: 7800, train loss: 6.3616, val loss: 6.6700\n",
            "Epoch: 3 Step: 8000, train loss: 6.3411, val loss: 6.6845\n",
            "Epoch: 3 Step: 8200, train loss: 6.3290, val loss: 6.6649\n",
            "Epoch: 3 Step: 8400, train loss: 6.3432, val loss: 6.6883\n",
            "Epoch: 3 Step: 8600, train loss: 6.3366, val loss: 6.6618\n",
            "Epoch: 3 Step: 8800, train loss: 6.3255, val loss: 6.6701\n",
            "Epoch: 3 Step: 9000, train loss: 6.3370, val loss: 6.6535\n",
            "Epoch: 3 Step: 9200, train loss: 6.3176, val loss: 6.6566\n",
            "Epoch: 3 Step: 9400, train loss: 6.3071, val loss: 6.6613\n",
            "Epoch: 3 Step: 9600, train loss: 6.3220, val loss: 6.6786\n",
            "Epoch: 3 Step: 9800, train loss: 6.3131, val loss: 6.6596\n",
            "Epoch: 4 Step: 0, train loss: 6.3239, val loss: 6.6652\n",
            "Epoch: 4 Step: 200, train loss: 6.3264, val loss: 6.6514\n",
            "Epoch: 4 Step: 400, train loss: 6.2880, val loss: 6.6664\n",
            "Epoch: 4 Step: 600, train loss: 6.3110, val loss: 6.6616\n",
            "Epoch: 4 Step: 800, train loss: 6.3063, val loss: 6.6254\n",
            "Epoch: 4 Step: 1000, train loss: 6.3142, val loss: 6.6553\n",
            "Epoch: 4 Step: 1200, train loss: 6.2705, val loss: 6.6511\n",
            "Epoch: 4 Step: 1400, train loss: 6.2860, val loss: 6.6596\n",
            "Epoch: 4 Step: 1600, train loss: 6.2874, val loss: 6.6222\n",
            "Epoch: 4 Step: 1800, train loss: 6.3010, val loss: 6.6241\n",
            "Epoch: 4 Step: 2000, train loss: 6.2778, val loss: 6.6649\n",
            "Epoch: 4 Step: 2200, train loss: 6.2951, val loss: 6.6430\n",
            "Epoch: 4 Step: 2400, train loss: 6.2471, val loss: 6.6420\n",
            "Epoch: 4 Step: 2600, train loss: 6.2885, val loss: 6.6168\n",
            "Epoch: 4 Step: 2800, train loss: 6.2826, val loss: 6.6226\n",
            "Epoch: 4 Step: 3000, train loss: 6.2471, val loss: 6.6304\n",
            "Epoch: 4 Step: 3200, train loss: 6.2450, val loss: 6.5686\n",
            "Epoch: 4 Step: 3400, train loss: 6.2550, val loss: 6.6249\n",
            "Epoch: 4 Step: 3600, train loss: 6.2722, val loss: 6.6487\n",
            "Epoch: 4 Step: 3800, train loss: 6.2323, val loss: 6.6055\n",
            "Epoch: 4 Step: 4000, train loss: 6.2726, val loss: 6.6328\n",
            "Epoch: 4 Step: 4200, train loss: 6.2548, val loss: 6.6065\n",
            "Epoch: 4 Step: 4400, train loss: 6.2331, val loss: 6.6029\n",
            "Epoch: 4 Step: 4600, train loss: 6.2607, val loss: 6.6513\n",
            "Epoch: 4 Step: 4800, train loss: 6.2303, val loss: 6.5997\n",
            "Epoch: 4 Step: 5000, train loss: 6.2264, val loss: 6.6152\n",
            "Epoch: 4 Step: 5200, train loss: 6.2283, val loss: 6.5837\n",
            "Epoch: 4 Step: 5400, train loss: 6.2230, val loss: 6.6229\n",
            "Epoch: 4 Step: 5600, train loss: 6.1997, val loss: 6.5826\n",
            "Epoch: 4 Step: 5800, train loss: 6.2395, val loss: 6.6081\n",
            "Epoch: 4 Step: 6000, train loss: 6.2234, val loss: 6.6287\n",
            "Epoch: 4 Step: 6200, train loss: 6.2151, val loss: 6.5935\n",
            "Epoch: 4 Step: 6400, train loss: 6.2077, val loss: 6.5854\n",
            "Epoch: 4 Step: 6600, train loss: 6.2044, val loss: 6.5817\n",
            "Epoch: 4 Step: 6800, train loss: 6.2380, val loss: 6.5748\n",
            "Epoch: 4 Step: 7000, train loss: 6.1971, val loss: 6.5941\n",
            "Epoch: 4 Step: 7200, train loss: 6.2157, val loss: 6.5813\n",
            "Epoch: 4 Step: 7400, train loss: 6.2075, val loss: 6.5465\n",
            "Epoch: 4 Step: 7600, train loss: 6.2066, val loss: 6.5768\n",
            "Epoch: 4 Step: 7800, train loss: 6.2137, val loss: 6.6068\n",
            "Epoch: 4 Step: 8000, train loss: 6.1852, val loss: 6.6137\n",
            "Epoch: 4 Step: 8200, train loss: 6.1886, val loss: 6.5770\n",
            "Epoch: 4 Step: 8400, train loss: 6.1882, val loss: 6.5987\n",
            "Epoch: 4 Step: 8600, train loss: 6.1950, val loss: 6.5863\n",
            "Epoch: 4 Step: 8800, train loss: 6.1858, val loss: 6.5767\n",
            "Epoch: 4 Step: 9000, train loss: 6.1658, val loss: 6.5769\n",
            "Epoch: 4 Step: 9200, train loss: 6.1839, val loss: 6.5692\n",
            "Epoch: 4 Step: 9400, train loss: 6.1823, val loss: 6.5702\n",
            "Epoch: 4 Step: 9600, train loss: 6.1639, val loss: 6.5849\n",
            "Epoch: 4 Step: 9800, train loss: 6.1795, val loss: 6.5539\n",
            " violently were the more collo. I shall for\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test it\n",
        "starter = torch.zeros((1,1), dtype=torch.long, device=device)\n",
        "print(tokenizer.decode(model.generate_new_text(starter, 100000)[0].tolist()))"
      ],
      "metadata": {
        "id": "CGrCGZ2W1c6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = 'state'\n",
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "4-RcZ2YpkNMV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMEZ9ZXxkbUT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}